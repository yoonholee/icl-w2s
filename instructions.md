## General Instructions

### Overview

This task is designed to assess your research skills, problem-solving abilities, and communication skills in a time-constrained environment. It comes in two parts:

- PART 1 (Research Iterating) You’ll perform a short investigation into using In-Context learning as a potential solution to Weak to Strong Generalisation.
- PART 2 (Research Communication) Then, you’ll create a presentation walking through what you tried, what you found, and what you would want to work on next (not necessarily in that order), and finally present your findings.

### Task Description

- On the MATH dataset (which the starter code below loads for you), choose a pair of models on the Anthropic API that perform at different levels on the task.
- Prompt the stronger model with few-shot examples using answers generated by the weaker model.
  - **You should determine a Performance Gap Recovered (PGR) metric** by comparing the performance of the weaker model when prompted with "gold" few-shot examples, the performance of the strong model when prompted with "weak-labelled" few-shot examples, and the performance of the strong model when prompted with "gold" few-shot examples.
- If you have time for additional followup, you could consider exploring any of the following ideas, or others that you’re more interested in!
  - how PGR varies with different gaps between strong and weak models (e.g. by varying which models you use for the strong and weak models)
  - how the PGR changes with the number of examples in the few-shot prompt.
  - how to tweak the few-shot prompt to improve the PGR (e.g. giving the strong model some indication of the strength of the labels)

### Deliverables

A set of slides summarizing your approach, results, and next steps, along with a copy of this colab notebook with all of your experiment code. You should feel free to turn this notebook into a python script and work on it in your local development environment if you'd prefer that.
  
Think of your final presentation as your slot in your weekly project meeting - what would you ask for clarity on? How would you provide additional context for your supervisors, collaborators, and mentor? It probably shouldn't be much longer or shorter than 10-15 minutes.

**Please send your presentation and your code to your interviewer before your call with them.**

### Time Allocation

Spend no more than **five hours** on this task (including time for creating your presentation). We understand this is a limited timeframe, and we're as interested in your ability to communicate your approach and thought process as well as the quality and volume of work produced.

### Allowed resources

Feel free to consult API references and use the internet as you'd like for this interview, as well as LLM/AI assistance if you'd find it helpful! We only ask that your work is your own and not the work of another person.

### Evaluation Criteria

We will assess your submission roughly equally across the following axes:

1. Problem understanding and setup
2. Clarity of thinking and approach
3. Implementation and experimentation
4. Analysis and interpretation of results
5. Communication of your process and findings

Remember, we're not looking for a complete solution in this timeframe. We're interested in seeing how you approach and think about complex problems.

### FAQ

- I'm getting rate-limited! What should I do?
  - You can adjust the `MAX_PARALLEL_REQUESTS` used when making API calls to try and get around rate-limiting -- if you find that this signfiicantly reduces your experimental throughput, we suggest also potentially reudcing the size of the dataset you're experimenting with, though we suggest using the full test dataset for all of your final results. Please flag any issues you have with the rate-limiting to your interviewer as well.
